{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step by step notebook for reproducing the workflow from RT pred manuscript \n",
    "\n",
    "Ensure that the requriements are met i.e.\n",
    "- rdkit \n",
    "- pytorch \n",
    "- deepchem\n",
    "- chemprop\n",
    "- etc.. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "#from rdkit import Chem\n",
    "from rdkit import RDLogger \n",
    "import deepchem as dc\n",
    "import os \n",
    "\n",
    "from functions.featurizers import get_METLIN_data, LogD_calculations, get_features\n",
    "from functions.data_splitting import data_splitter, feature_splitter_csv, feature_splitter_diskdatasets\n",
    "\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*') # disable rdkit log\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization and data splitting\n",
    "\n",
    "This workflow is run using the METLIN SMRT Dataset published by Domingo-Almenara et al. https://www.nature.com/articles/s41467-019-13680-7 \n",
    "\n",
    "But any dataset could be used, however, it must contain columns 'rt' and 'smiles'\n",
    "\n",
    "By default we remove non-retained compounds from the METLIN SMRT dataset and subsample (2000, randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to:  ../data/metlin_smrt\\sample_dataset_2000_datapoints.csv\n",
      "             id                                             smiles      rt\n",
      "45507  53143824  CC(C)c1noc(-c2cc(=O)n(CC(=O)Nc3ccc(N(C)C)cc3)c...   737.1\n",
      "1182    2966969  CCCCN1C(=O)[C@](N=C(O)c2ccccc2OC)(C(F)(F)F)C2=...  1076.0\n",
      "29828  20952107             OC(=NCCc1ccco1)C1CCN(c2nc3cccnc3s2)CC1   697.1\n"
     ]
    }
   ],
   "source": [
    "get_METLIN_data(sampling = 2000, only_retained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of features that we use for modeling. \n",
    "\n",
    "- LogD descriptor set (pH 0.5 to 7.4)\n",
    "- ECFP4-2048 fingerprints\n",
    "- RDKit descriptors \n",
    "- molecular graph convolutions \n",
    "\n",
    "based on the feature_list ``` feature_list = ['logD', 'ecfp4', 'rdkit', 'molgraphconv]``` it is possible to define which features to be calculated. \n",
    "\n",
    "Note that the ECFP4 and RDKit descriptors come in two variants: a flat .csv file or a DeepChem DiskData object. This choice will depend on downstream application and models.\n",
    "\n",
    "\n",
    "OBS! LogD calculations are based on the proprietary software cxcalc from Chemaxon (https://docs.chemaxon.com/display/docs/cxcalc-command-line-tool.md). A path to a chemaxon licence is needed for this calculation, as well as a specified path to the chemaxon tool. If not provided, the LogD calculations are skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "path_to_data = '../data/metlin_smrt/sample_dataset_2000_datapoints.csv'\n",
    "path_to_features = '../data/metlin_smrt/features/' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemAxon-based LogD calculations - to .CSV\n",
      "*** NA values in: ../data/metlin_smrt/features/logd_calculations\n",
      "ECFP4 Featurization - to DiskDataset\n",
      "ECFP4 Featurization - to .CSV\n",
      "RDKit Descriptors - to diskdataset\n",
      "RDKit Descriptors - to .CSV\n",
      "MolGraphConv Feat - to diskdataset\n"
     ]
    }
   ],
   "source": [
    "feature_list = ['logD', \n",
    "                'ecfp4', \n",
    "                'rdkit', \n",
    "                'molgraphconv'\n",
    "                ]\n",
    "\n",
    "get_features(path_to_data, \n",
    "             path_to_features, feature_list, \n",
    "             path_to_chemaxon_licence= r\"G:\\Nuevolution\\ChemAxon\\licenses\\license.cxl\", \n",
    "             path_to_chemaxon_tools = r\"C:\\nuevolution\\knime_temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting \n",
    "\n",
    "The data is split into train/test. In addition the train dataset is split 5 times to allow for 5-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base directory for the split data\n",
    "path_to_splits = '../data/metlin_smrt/data_splits/'\n",
    "if not os.path.exists(path_to_splits):\n",
    "    os.makedirs(path_to_splits)\n",
    "\n",
    "data_splitter(path_to_data, path_to_splits, number_of_splits = 5, seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will take the features already calculated and bundle them according to the above splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* splitting the .CSV-based features according to the data splits\n",
    "feature_splitter_csv(path_to_features, path_to_splits, save_folder_name = 'cv_splits')\n",
    "\n",
    "\n",
    "#* splitting the diskDataset-based features according to the data splits\n",
    "feature_splitter_diskdatasets(path_to_features,path_to_splits, save_folder_name = 'cv_splits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamol_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
