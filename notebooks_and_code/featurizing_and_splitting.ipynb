{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step by step notebook for reproducing the workflow from RT pred manuscript \n",
    "\n",
    "Ensure that the requriements are met i.e.\n",
    "- rdkit \n",
    "- pytorch \n",
    "- deepchem\n",
    "- chemprop\n",
    "- etc.. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from functions.featurizers import get_METLIN_data, get_features \n",
    "from functions.data_splitting import data_splitter, feature_splitter_csv, feature_splitter_diskdatasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization and data splitting\n",
    "\n",
    "This workflow is run using the METLIN SMRT Dataset published by Domingo-Almenara et al. https://www.nature.com/articles/s41467-019-13680-7 \n",
    "\n",
    "But any dataset could be used, however, it must contain columns 'rt' and 'smiles'\n",
    "\n",
    "By default we remove non-retained compounds from the METLIN SMRT dataset and subsample (2000, randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to:  ../data/metlin_smrt\\sample_dataset_2000_datapoints.csv \n",
      "\n",
      "             id                                             smiles     rt\n",
      "21097  46391263  CCCN=C(O)[C@H]1CCCN(c2nc3ncn(CC(=O)Nc4ccc(OCC)...  719.7\n",
      "61199  53182779           O=C1NCCCn2cc(S(=O)(=O)Nc3cccc(Cl)c3)cc21  680.0\n",
      "22744  47025677                      OC(=NCCCn1cccn1)c1cn2ccccc2n1  570.3\n"
     ]
    }
   ],
   "source": [
    "path_to_data = get_METLIN_data(sampling = 2000, only_retained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of features that we use for modeling. \n",
    "\n",
    "- LogD descriptor set (pH 0.5 to 7.4)\n",
    "- ECFP4-2048 fingerprints\n",
    "- RDKit descriptors \n",
    "- molecular graph convolutions \n",
    "\n",
    "based on the feature_list ``` feature_list = ['logD', 'ecfp4', 'rdkit', 'molgraphconv]``` it is possible to define which features to be calculated. \n",
    "\n",
    "Note that the ECFP4 and RDKit descriptors come in two variants: a flat .csv file or a DeepChem DiskData object. This choice will depend on downstream application and models.\n",
    "\n",
    "\n",
    "OBS! LogD calculations are based on the proprietary software cxcalc from Chemaxon (https://docs.chemaxon.com/display/docs/cxcalc-command-line-tool.md). A path to a chemaxon licence is needed for this calculation, as well as a specified path to the chemaxon tool. If not provided, the LogD calculations are skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemAxon-based LogD calculations - to .CSV\n",
      "*** NA values in: ../data/metlin_smrt/features/logd_calculations\n",
      "ECFP4 Featurization - to DiskDataset\n",
      "ECFP4 Featurization - to .CSV\n",
      "RDKit Descriptors - to diskdataset\n",
      "RDKit Descriptors - to .CSV\n",
      "MolGraphConv Feat - to diskdataset\n"
     ]
    }
   ],
   "source": [
    "path_to_features = '../data/metlin_smrt/features/' \n",
    "if not os.path.exists(path_to_features):\n",
    "    os.makedirs(path_to_features)\n",
    "\n",
    "feature_list = ['logD', \n",
    "                'ecfp4', \n",
    "                'rdkit', \n",
    "                'molgraphconv'\n",
    "                ]\n",
    "\n",
    "get_features(path_to_data, \n",
    "             path_to_features, feature_list, \n",
    "             path_to_chemaxon_licence= path_to_chemaxon_licence, \n",
    "             path_to_chemaxon_tools = path_to_chemaxon_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting \n",
    "\n",
    "The data is split into train/test. In addition the train dataset is split 5 times to allow for 5-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_splits = '../data/metlin_smrt/data_splits/'\n",
    "if not os.path.exists(path_to_splits):\n",
    "    os.makedirs(path_to_splits)\n",
    "\n",
    "data_splitter(path_to_data, path_to_splits, number_of_splits = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will take the features already calculated and bundle them according to the above splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* splitting the .CSV-based features according to the data splits\n",
    "feature_splitter_csv(path_to_features, path_to_splits, save_folder_name = 'cv_splits')\n",
    "\n",
    "\n",
    "#* splitting the diskDataset-based features according to the data splits\n",
    "feature_splitter_diskdatasets(path_to_features,path_to_splits, save_folder_name = 'cv_splits')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamol_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
